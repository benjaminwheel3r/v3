---
title: "R Notebook"
output: html_notebook
---

```{r "setup", include=FALSE}
require("knitr")
opts_knit$set(root.dir = "C:/Temp/FINAL_INPUTS/Box Sync/R/v4/GWR/GWR_Analysis/Results_Bivariate/Images/FINAL_MODEL/whhinc")
```


```{r} 
#install.packages("shinyjs")
require(sp)
library(car)
library(sp)
library(rgdal)
library(RColorBrewer)
library(spdep)
#library(lattice)
#library(latticeExtra)
#library(maptools)
library(tmap)
#library(spgwr)
library(GWmodel)
library(geojsonio)
library(spdplyr)
library(rmapshaper)
#prevents lat long rounding
options("scipen" = 100)

```

```{r}
Candidate = "TRUMP"
#reads in Countylayer  - WGS1984 - geographic Coordinate system
setwd("C:/Temp/FINAL_INPUTS/Box Sync/R/v4/GWR/GWR_Analysis")
co = readOGR(dsn = getwd(),layer = "NY_CNTY",integer64="warn.loss")
df_co = data.frame(co)
spdf_co = SpatialPolygonsDataFrame(co,df_co)

d3 <- read.table("C:/Temp/FINAL_INPUTS/Box Sync/R/v4/v3_AllTags_002_AllSources_analysis_v3_310.csv",
                 header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
d3$PopDens <- log(d3$TotPop/d3$SqMiles)
d3$perc_white_comb <- d3$White_and_combination/d3$TotPop
d3$perc_white <- d3$White_only/d3$TotPop
d3$perc_Fem <- d3$FemOver18/d3$PopOver18
d3$Estimate_MedianIncome_2015
#Sorts etc
sp = spdf_co[order(spdf_co$NAME), ]
d3j = d3[order(d3$County), ]

#THis is a dumb intermediate
df1 <- data.frame(d3j[ which(d3j$CANDIDATE==Candidate), ])
outvar = "C:/Temp/FINAL_INPUTS/Box Sync/R/v4/v3_AllTags_002_AllSources_analysis_v3_310_subset.csv"
write.csv(df1,outvar,na="0")


df = read.table(outvar,header=TRUE, sep=",", na.strings="NA", dec=".",strip.white=TRUE)
spdf_co2 = merge(sp,df,by=(intersect(by.x,by.y)),by.x = "NAME", by.y = "County")

DeVar = "Candidate_VS"
InDeVar= c("Perc_BachelorsDeg_and_higher","perc_Fem","perc_white","PopDens","MedianAge_Total","Candidate_TS17", "Candidate_TS18", "Candidate_TS19b4") #, "Candidate_TS17", "Candidate_TS18", "Candidate_TS_b4"

model.sel <- gwr.model.selection(DeVar,InDeVar, data=spdf_co2,bw=30,approach="aic", adaptive=T,kernel="bisquare",dMat=NULL,p=2, theta=0, longlat=T)
model.list <- model.sel[[1]]
gwr.model.view(DeVar, InDeVar, model.list)

#add variable for method and data to plot.
column = 3
plot(model.sel[[2]][,column], col = "black", pch = 20, lty = 5, 
	main = "Alternative view of GWR model selection procedure", 
	ylab = "AICc", xlab = "Model number", type = "b")

ruler.vector <- model.sel[[2]][,column]
lvar <- length(InDeVar)

sorted.models <- gwr.model.sort(model.sel,lvar, ruler.vector)

model.list <- sorted.models[[1]]
gwr.model.view(DeVar, InDeVar, model.list)
#bandwidth, AIC, AICc, RSS
model.sel[[2]] 

plot(sorted.models[[2]][,column], col = "black", pch = 20, lty = 5, 
	main = "Alternative view of GWR model selection procedure", 
	ylab = "AICc", xlab = "Model number", type = "b")

sorted.models[[2]][,column]
sorted.models[[1]]

```

The below comes from the code example on p.7 of the GWModel Documentation.
See p.27 on Collinearity...

```{r bandwidth selection}
DM <- gw.dist(dp.locat = coordinates(spdf_co2))
```

```{r}
lm.global <- lm(Candidate_VS~Candidate_TS18+Candidate_TS19b4+Candidate_TS17+Perc_BachelorsDeg_and_higher+perc_Fem+MedianAge_Total+Estimate_MedianIncome_2015+perc_white, data = spdf_co2)
summary(lm.global)
#Candidate_TS_b4+PopDens+perc_white
mod = vif(lm.global) # variance inflation factors 
mod2 = sqrt(vif(lm.global)) > 2 # problem?
mod
#removed - population Density due to Multi-Collinearity with other spatial structures.
```

```{r}
f1 <- Candidate_VS~Candidate_TS18+Candidate_TS19b4+Candidate_TS17+Perc_BachelorsDeg_and_higher+perc_Fem+MedianAge_Total+perc_white+Estimate_MedianIncome_2015
m1 <- lm(f1, data = spdf_co2)
summary(m1)

lm.global <- lm(Candidate_VS~Candidate_TS18+Candidate_TS19b4+Candidate_TS17+Perc_BachelorsDeg_and_higher+perc_Fem+MedianAge_Total+perc_white+Estimate_MedianIncome_2015, data = spdf_co2)
summary(lm.global)
lm.global$residuals
```


```{r}
lm.global <- lm(Candidate_VS~Candidate_TS18+Candidate_TS19b4+Candidate_TS17+Perc_BachelorsDeg_and_higher+perc_Fem+MedianAge_Total+perc_white+Estimate_MedianIncome_2015, data = spdf_co2)
summary(lm.global)

mod = vif(lm.global) # variance inflation factors 
mod2 = sqrt(vif(lm.global)) > 2 # problem?
mod


bw.gwr.1 <- bw.gwr(Candidate_VS~Candidate_TS18+Candidate_TS19b4+Candidate_TS17+Perc_BachelorsDeg_and_higher+perc_Fem+MedianAge_Total+perc_white+Estimate_MedianIncome_2015, data = spdf_co2, approach = "AICc",
	kernel = "bisquare", adaptive = TRUE, longlat = TRUE)
bw.gwr.2 <- bw.gwr(Candidate_VS~Candidate_TS18+Candidate_TS19b4+Candidate_TS17+Perc_BachelorsDeg_and_higher+perc_Fem+MedianAge_Total+perc_white+Estimate_MedianIncome_2015, data = spdf_co2, approach = "cv", kernel = "bisquare", adaptive=TRUE)
bw.gwr.1
bw.gwr.2

#Model Selection

model.sel <- model.selection.gwr(DeVar ,InDeVar, data = spdf_co2, kernel = "bisquare", adaptive = TRUE, bw = bw.gwr.1) 
sorted.models <- model.sort.gwr(model.sel, numVars = length(InDeVar), ruler.vector = model.sel[[2]][,2]) 
model.list <- sorted.models[[1]]
model.list
model.view.gwr(DeVar, InDeVar, model.list = model.list)
model.sel

plot(sorted.models[[2]][,3], col = "black", pch = 20, lty = 5, 
	main = "Alternative view of GWR model selection procedure",  
	ylab = "AICc", xlab = "Model number", type = "b")


gwr.res <- gwr.basic(Candidate_VS~Candidate_TS18+Candidate_TS19b4+Candidate_TS17+Perc_BachelorsDeg_and_higher+perc_Fem+MedianAge_Total+perc_white+Estimate_MedianIncome_2015,
                     data = spdf_co2, bw = bw.gwr.2, kernel = "bisquare", adaptive = TRUE, F123.test = FALSE)

writeGWR(gwr.res)
```

```{r}
sdf <- gwr.res$SDF
sdf$residual_ols <- lm.global$residuals
sdf$yhat_ols <- lm.global$fitted.values

adjustedtval <- gwr.t.adjust(gwr.res)
adjustedtval$results$t
helpme <- cbind(sdf,adjustedtval$results$t)

char = "_TV"
colm = colnames(sdf@data)[grepl(char, colnames(sdf@data))]
suffix = "_wBoth_noM"


for (i in colm)
{

map = tm_shape(sdf) +tm_fill(col = i, breaks = c(-Inf,-4, -2.00,-1.67, 0, 1.67, 2.00, 4, Inf)) +  tm_legend(outside = FALSE, text.size = .8)+tm_borders()
print(map)
save_tmap(tm = map, filename = paste(i,suffix,".png",sep = ''))
}

n = 8
colm = colnames(sdf@data)[1:(n+1)]
suffix = "_Coefs_TV"
f <- c()
for (i in colm)
{
  val90 <- sdf[eval(parse(text=paste("abs(sdf@data$",i,"_TV) > 1.701",sep =''))),]
  val95 <- sdf[eval(parse(text=paste("abs(sdf@data$",i,"_TV) > 2.048",sep =''))),]
  val99 <- sdf[eval(parse(text=paste("abs(sdf@data$",i,"_TV) > 2.763",sep =''))),]
  col90 = eval(parse(text=paste("val@data$",i,sep ='')))
  col95 = eval(parse(text=paste("val@data$",i,sep ='')))
  col99 = eval(parse(text=paste("val@data$",i,sep ='')))
  f<- c(f,paste(i,'90',
                min(col90),max(col90),median(col90),NROW(col90)
              ,sep = ',')
        )
  f<- c(f,paste(i,'95',
                min(col95),max(col95),median(col95),NROW(col95)
              ,sep = ',')
        )
  f<- c(f,paste(i,'99',
                min(col99),max(col99),median(col99),NROW(col99)
              ,sep = ',')
        )
  
  if(i == "Estimate_MedianIncome_2015")
{  val <- sdf[eval(parse(text=paste("abs(sdf@data$",i,"_TV) > 1.701",sep =''))),]
Coef_map = tm_shape(sdf)+tm_borders()+tm_shape(val) +tm_fill(col = i) + tm_legend(outside = F, text.size =.8) + tm_borders()+tm_layout(legend.format = list(format ='f', scientific = TRUE,digits = 6))

try(print(Coef_map))
try(save_tmap(tm = Coef_map, filename = paste(i,suffix,".png",sep = '')))
rm(Coef_map)}

  else{val <- sdf[eval(parse(text=paste("abs(sdf@data$",i,"_TV) > 1.67",sep =''))),]
Coef_map = tm_shape(sdf)+tm_borders()+tm_shape(val) +tm_fill(col = i) + tm_legend(outside = F, text.size =.8) + tm_borders()

try(print(Coef_map))
try(save_tmap(tm = Coef_map, filename = paste(i,suffix,".png",sep = '')))
rm(Coef_map)
}
}

write(f, file = 'data_read_out.csv')
```

```{r}
tmap_mode("plot")
est = c(.3,.4,.5,.6,.7,.8,.9)
r2 = tm_shape(sdf) +tm_fill(col = "Local_R2") +  tm_legend(outside = FALSE, text.size = .8)+tm_borders()
save_tmap(tm = r2, filename = paste("r2",suffix,".png",sep = ''))
r2

ylayers = c('y','yhat','yhat_ols')
for (i in ylayers)
{
y = tm_shape(sdf) +tm_fill(col = i, breaks = est, palette = c('white','grey','black')) +  tm_legend(outside = FALSE, text.size = .8)+tm_borders()
save_tmap(tm = y, filename = paste(i,suffix,".png",sep = ''))
print(y)
}

break4 = c(-Inf,-.10,-0.05, -0.02,-.01, 0, 0.01, 0.02, 0.05,.10, Inf)
layers = list("residual","residual_ols", "Stud_residual")
for (i in layers)
{
res= tm_shape(sdf) +tm_fill(col = i,breaks = if(i=="Stud_residual"){NULL} else {break4},palette = 'RdYlBu',legend.is.portrait = TRUE) +  tm_legend( outside = if(i=="Stud_residual"){TRUE} else {TRUE},  text.size = .8)+tm_borders()+tm_layout(frame = FALSE)
save_tmap(tm = res, filename = paste(i,suffix,".png",sep = ''))
print(res)
}
#break1 = c(-Inf,-0.05, -0.02,-.01, 0, 0.01, 0.02, 0.05, Inf)
#break2 = c(-Inf,-0.05, -0.02, 0, 0.02, 0.05, Inf)
#break3 = c(-Inf,-.10,-0.05, -0.02, 0, 0.02, 0.05, .10, Inf)
```

```{r determining Neighbours}
nb <- poly2nb(spdf_co2,queen=TRUE,row.names = spdf_co2$NAME)
nb[43][1] = c(as.integer(24))
#adjusting for Staten Island (Richmond County,#43)  connection to Kings County(#24) via Bridge.
nb_rook <- poly2nb(spdf_co2,queen=FALSE)
nb_snap <- poly2nb(spdf_co2,
                   queen = TRUE,
                   snap = 0
                     )

```

### Computing Weights
http://geog.uoregon.edu/bartlein/old_courses/geog414f03/lectures/lec09.htm
this link provides a description of code and an example of using different values for lags. It may be worth considering...
```{r Computing Weights}
lw = nb2listw(nb, style="W", zero.policy = TRUE)
lw
moran.mc(sdf$residual_ols,lw,999)
morantest2 = lm.morantest(m1,lw)
morantest2

moran.mc(sdf$residual_ols,lw,999)

moran.test(sdf$residual,lw)
```

```{r histogram}
MIi =morantest2$estimate[1][1]
n <- 699   # Define the number of simulations
I.r <- vector()  # Create an empty vector

for (i in 1:n){
  # Randomly shuffle income values
  x <- sample(sdf$residual_ols, replace=FALSE)
  # Compute new set of lagged values
  x.lag <- lag.listw(lw, x)
  # Compute the regression slope
  M.r <- lm(x.lag ~ x)
  I.r[i] <- coef(M.r)[2]
}

# Plot histogram of simulated Moran's I values
# then add our observed Moran's I value to the plot
png(filename='Plotted_MoransI_histogram.png')
plot.new()
hist(I.r, main=NULL, plot = TRUE, xlim = c(-.6,.6),ylim =c(0,175))
abline(v=MIi, col="red")
text(x = MIi,y = 100,labels = paste("Moran's I:",round(MIi,4)),pos=2,cex=1.0,las=2,srt =90)
dev.off()

```


```{r Histogram GWR}
moran.mc(sdf$Stud_residual,lw,999)
test_after = moran.mc(sdf$residual,lw,999)
test_after

MIi =test_after$statistic
n <- 999   # Define the number of simulations
I.r <- vector()  # Create an empty vector

for (i in 1:n){
  # Randomly shuffle income values
  x <- sample(sdf$residual, replace=FALSE)
  # Compute new set of lagged values
  x.lag <- lag.listw(lw, x)
  # Compute the regression slope
  M.r <- lm(x.lag ~ x)
  I.r[i] <- coef(M.r)[2]
}

# Plot histogram of simulated Moran's I values
# then add our observed Moran's I value to the plot
png(filename='Plotted_MoransI_histogram_GWR.png')
plot.new()
hist(I.r, main=NULL, plot = TRUE, xlim = c(-.5,.5),ylim =c(0,250))
abline(v=MIi, col="red")
text(x = MIi,y = 100,labels = paste("Moran's I:",round(MIi,4)),pos=2,cex=1.0,las=2,srt =90)
dev.off()
```


```{r SE per County}
char = "_SE"
colm = colnames(sdf@data)[grepl(char, colnames(sdf@data))]

for (i in colm)
{
print(spplot(gwr.res$SDF, i, key.space = "right", 
	main = paste("Standard Error for",i),
	sp.layout = map.layout))
}
tm_shape(sdf) +tm_fill(col = "Local_R2") +  tm_legend(outside = TRUE, text.size = .8)
```
```{r Coefficient_Maps}
n = 8
colm = colnames(sdf@data)[1:(n+1)]

for (i in colm)
{
val =sdf@data[,paste(i,"_TV",sep ='')]
val > -1.96
print(tm_shape(sdf) +tm_fill(col = i) + tm_legend(outside = TRUE, text.size = .8)+tm_borders())
}

```
```{r}

```
